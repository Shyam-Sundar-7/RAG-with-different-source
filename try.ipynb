{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # type: ignore\n",
    "import boto3\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "import numpy as np\n",
    "from dotenv  import load_dotenv\n",
    "load_dotenv()\n",
    "import shutil\n",
    "\n",
    "def load_file(file_name):\n",
    "    loader=[]\n",
    "    # print(file_name.split(\".\")[-1])\n",
    "    if file_name.split('.')[-1] == \"pptx\":\n",
    "        loader = UnstructuredPowerPointLoader(file_name).load()\n",
    "    elif file_name.split('.')[-1] == \"pdf\":\n",
    "        loader = PyPDFLoader(file_name).load()    \n",
    "    elif file_name.split('.')[-1] == \"docx\":\n",
    "        loader = Docx2txtLoader(file_name).load()\n",
    "    elif file_name.split('.')[-1] == \"html\":\n",
    "        loader = UnstructuredHTMLLoader(file_name).load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # separator=\"\\n\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=300\n",
    "        )\n",
    "    pages = text_splitter.split_documents(loader)\n",
    "    return pages\n",
    "\n",
    "\n",
    "def file_to_chunks(folder):\n",
    "    pages=[]\n",
    "    for file_name in os.listdir(f\"{folder}\"):\n",
    "        pages.extend(load_file(f\"{folder}\\\\{file_name}\"))\n",
    "    if folder != \"Local_data\":\n",
    "        shutil.rmtree(f\"{folder}\")\n",
    "    return pages\n",
    "\n",
    "def azure_data_download(AZURE_CONNECTION_STRING,CONTAINER_NAME):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\n",
    "    container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "    if not os.path.exists(\"Azure_data\"):\n",
    "        os.mkdir(\"Azure_data\")\n",
    "    for file_name in container_client.list_blobs():\n",
    "        blob_client = container_client.get_blob_client(file_name)\n",
    "        with open(f\"Azure_data\\\\{file_name.name}\", \"wb\") as file:\n",
    "            data = blob_client.download_blob().readall()\n",
    "            file.write(data)\n",
    "\n",
    "\n",
    "def aws(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, BUCKET_NAME,object_name):\n",
    "        # Create an S3 client\n",
    "    s3 = boto3.client('s3',\n",
    "                    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                    aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    # List objects in the bucket\n",
    "    response = s3.list_objects_v2(Bucket=BUCKET_NAME)\n",
    "\n",
    "    if not os.path.exists(\"S3_data\"):\n",
    "        os.mkdir(\"S3_data\")\n",
    "\n",
    "    # Download files in the 'data' object\n",
    "    for i in response.get('Contents',[]):\n",
    "        if i['Key'].split('/')[-1] != \"\" and i['Key'].split('/')[0] == object_name:\n",
    "            # print(i['Key'])\n",
    "            file_path = os.path.join(\"S3_data\", i['Key'].split('/')[-1])\n",
    "            # print(file_path)\n",
    "            s3.download_file(BUCKET_NAME, i['Key'], file_path)\n",
    "\n",
    "\n",
    "def l(h):\n",
    "    d=\"\"\n",
    "    for i in h:\n",
    "        for _,j in i.items():\n",
    "            d=d+f\"{j} \\n\"\n",
    "    if d == \"\":\n",
    "        d = \"No history found\"\n",
    "    return d\n",
    "\n",
    "\n",
    "def generate_queries(query):\n",
    "\n",
    "    # Multi Query: Different Perspectives\n",
    "    template = \"\"\"You are an AI language model assistant. Your task is to generate Four \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "    prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "    generate_querie = (\n",
    "        prompt_perspectives \n",
    "        | ChatOpenAI(temperature=0) \n",
    "        | StrOutputParser() \n",
    "        | (lambda x: x.split(\"\\n\"))\n",
    "        | (lambda x: [query] + x)\n",
    "    )\n",
    "    return generate_querie \n",
    "\n",
    "def keyword_extractor():\n",
    "    prompt=\"\"\"\n",
    "    You are an AI language model assistant. Your task is to help the user identify key terms in their query.\n",
    "\n",
    "    Please list the main keywords you want to extract from your query.\n",
    "\n",
    "    query: {query}\n",
    "    \"\"\"\n",
    "    prompt_perspectives=ChatPromptTemplate.from_template(prompt)\n",
    "    generate_querie = (\n",
    "        prompt_perspectives \n",
    "        | ChatOpenAI(temperature=0) \n",
    "        | StrOutputParser() )\n",
    "    return generate_querie\n",
    "\n",
    "def _get(a):\n",
    "    dd=[]\n",
    "    for s in a:\n",
    "        dd.extend(s)\n",
    "    return dd\n",
    "\n",
    "def get_unique_documents(doc_list):\n",
    "    seen_content = set()\n",
    "    unique_documents = []\n",
    "    \n",
    "    for doc in doc_list:\n",
    "        content = doc.page_content\n",
    "        if content not in seen_content:\n",
    "            seen_content.add(content)\n",
    "            unique_documents.append(doc)\n",
    "    \n",
    "    del seen_content\n",
    "    \n",
    "    return unique_documents\n",
    "\n",
    "def meta(s):\n",
    "    f=[]\n",
    "    for i in s:\n",
    "        d=\"\"\n",
    "        for i,y in i.metadata.items():\n",
    "            d=d+f\"{i} : {y} \\n\"\n",
    "        f.append(d)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = file_to_chunks(\"Local_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"pages.pkl\", \"wb\") as f:\n",
    "#     # pickle.dump(pages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pages.pkl\", \"rb\") as f:\n",
    "    pages1 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pages==pages1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# db = FAISS.from_documents(pages, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.save_local(\"Local_vectorstore\")\n",
    "\n",
    "db=FAISS.load_local(\"Local_vectorstore\",OpenAIEmbeddings(),allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query=\"tell me more about shyam sundar's education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"tell me more about shyam sundar's education\",\n",
       " '1. What are the educational qualifications of Shyam Sundar?',\n",
       " \"2. Can you provide details about Shyam Sundar's academic background?\",\n",
       " '3. What is known about the educational history of Shyam Sundar?',\n",
       " '4. Could you share information regarding the schooling and higher education of Shyam Sundar?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries(Query).invoke(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shyams\\Downloads\\RAG with different source\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "faiss_retriever=db.as_retriever(search_kwargs={'k': 10})\n",
    "\n",
    "Bm25_retriever = BM25Retriever.from_documents(pages)\n",
    "Bm25_retriever.k = 10\n",
    "\n",
    "key_chain=keyword_extractor() | Bm25_retriever\n",
    "map_chain=generate_queries | faiss_retriever.map() | _get | get_unique_documents\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "retrievers=[map_chain, key_chain], weights=[0.5, 0.5]\n",
    ")\n",
    "model = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "compressor = CrossEncoderReranker(model=model, top_n=4)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")\n",
    "\n",
    "final_prompt=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\"\"\"\n",
    "\n",
    "final_prompt_perspectives=ChatPromptTemplate.from_template(final_prompt)\n",
    "       \n",
    "llm_chain3= ({\"context\": itemgetter(\"query\") | compression_retriever,\n",
    "            \"question\":itemgetter(\"query\")}\n",
    "            | \n",
    "            RunnableParallel({\n",
    "                \"response\":  final_prompt_perspectives | ChatOpenAI(temperature=0) | StrOutputParser() ,\n",
    "                \"context\": itemgetter(\"context\")\n",
    "            })\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
      "Failed to batch ingest runs: ReadTimeout(ReadTimeoutError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Read timed out. (read timeout=90.001)\"))\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "s=llm_chain3.invoke({\"query\":Query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Shyam Sundar holds an M.Tech in Modelling and Simulation from the Defence Institute of Advanced Technology in Pune with a GPA of 7.95 obtained in May 2023. He also has a B.Tech in Chemical Engineering from the National Institute of Technology in Tiruchirappalli with a GPA of 7.65 earned in May 2021. Additionally, he has taken relevant coursework in Data Structures, Machine Learning, Deep Learning, and other technical skills.',\n",
       " 'context': [Document(page_content='Shyam Sundar\\n5,kavimani steet, Pankajam colony, 3rd cross street, Madurai, India - 625009\\n♂phone+91-9080765574 /envel⌢pemailshyamsundar.2022@gmail.com /linkedinshyamsundar007 /githubShyam-Sundar-7♂laptopPortfolio\\nProjects\\nLLM-Powered Coupon Recommender /github/video |Python, Streamlit, Langchain, OpenAI November 2023\\n•Developed a QA system for e-commerce with personalized coupon recommendations using OpenAI’s LLMs.\\n•Streamlined user interactions through a Streamlit interface and Langchain for real-world scenario simulations.\\n•Incorporated FAISS for refined recommendation processes.\\nPeopleCare Insurance Prediction /github |Python, Jupyter, Azure Cloud, Flask, Docker October 2023\\n•Expanded PeopleCare into vehicle insurance with a predictive model for effective customer targeting.\\n•Thorough analysis of customer behavior and data cleaning for accurate predictive modeling.\\n•Achieved 80% prediction accuracy using LightGBM.', metadata={'source': 'Local_data\\\\resume.pdf', 'page': 0}),\n",
       "  Document(page_content=\"About the reviewer\\nHitesh Hinduja is an ardent AI enthusiast working as a Senior Manager in AI at Ola \\nElectric, where he leads a team of 20+ people in the areas of machine learning, deep \\nlearning, statistics, computer vision, natural language processing, and reinforcement \\nlearning. He has filed 14+ patents in India and the US and has numerous research \\npublications under his name. Hitesh has been associated in research roles at India's \\ntop B-schools: Indian School of Business, Hyderabad, and the Indian Institute of \\nManagement, Ahmedabad. He is also actively involved in training and mentoring and has \\nbeen invited as a guest speaker by various corporates and associations across the globe.\", metadata={'source': 'Local_data\\\\Natu Lauchande - Machine Learning Engineering with MLflow_ Manage the end-to-end machine learning life cycle with MLflow (2021, Packt Publishing) - libgen.li.pdf', 'page': 4}),\n",
       "  Document(page_content='Contributors\\nAbout the author\\nNatu Lauchande is a principal data engineer in the fintech space currently tackling \\nproblems at the intersection of machine learning, data engineering, and distributed \\nsystems. He has worked in diverse industries, including biomedical/pharma research, \\ncloud, fintech, and e-commerce/mobile. Along the way, he had the opportunity to be \\ngranted a patent (as co-inventor) in distributed systems, publish in a top academic \\njournal, and contribute to open source software. He has also been very active as a speaker \\nat machine learning/tech conferences and meetups.', metadata={'source': 'Local_data\\\\Natu Lauchande - Machine Learning Engineering with MLflow_ Manage the end-to-end machine learning life cycle with MLflow (2021, Packt Publishing) - libgen.li.pdf', 'page': 3}),\n",
       "  Document(page_content='•Central global model collected weight updates from six randomly selected client models, averaging the contributions, and\\ndisseminated the updated global model to all participating clients.\\n•Effected a commendable accuracy rate of 78% upon successful completion of the training process, demonstrating the effectiveness\\nof the federated learning approach in preserving data security and privacy while maintaining model performance.\\nEducation\\nDefence Institute of Advanced Technology Pune, IN\\nM.Tech in Modelling and Simulation, GPA: 7.95 May 2023\\nNational Institute of Technology Tiruchirappalli, IN\\nB.Tech in Chemical Engineering, GPA: 7.65 May 2021\\nRelevant Coursework\\n•Data Structures\\n•Advanced Numerical Techniques•Machine Learning\\n•Data Science•Deep Learning\\n•Computer Graphics\\nTechnical Skills\\nLanguages : Python, C/C++, SQL (Postgres), Matlab, Latex\\nFrameworks : Pytorch, Tensorflow, Flask, Pytorch Lightning\\nTools/Platform : Tableau, Power Bi, Azure, Git, Jupyter, Docker', metadata={'source': 'Local_data\\\\resume.pdf', 'page': 0})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shyam Sundar holds an M.Tech in Modelling and Simulation from the Defence Institute of Advanced Technology in Pune with a GPA of 7.95 obtained in May 2023. He also has a B.Tech in Chemical Engineering from the National Institute of Technology in Tiruchirappalli with a GPA of 7.65 earned in May 2021. Additionally, he has taken relevant coursework in Data Structures, Machine Learning, Deep Learning, and other technical skills.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source : Local_data\\\\resume.pdf \\npage : 0 \\n',\n",
       " 'source : Local_data\\\\Natu Lauchande - Machine Learning Engineering with MLflow_ Manage the end-to-end machine learning life cycle with MLflow (2021, Packt Publishing) - libgen.li.pdf \\npage : 4 \\n',\n",
       " 'source : Local_data\\\\Natu Lauchande - Machine Learning Engineering with MLflow_ Manage the end-to-end machine learning life cycle with MLflow (2021, Packt Publishing) - libgen.li.pdf \\npage : 3 \\n',\n",
       " 'source : Local_data\\\\resume.pdf \\npage : 0 \\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta(s[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
